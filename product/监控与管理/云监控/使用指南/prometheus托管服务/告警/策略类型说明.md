

云监控为 Kubernetes 集群预设了 [Master 组件](#kubernetes-master-.E7.BB.84.E4.BB.B6)，[Kubelet](#kubelet)，[资源使用](#kubernetes-.E8.B5.84.E6.BA.90.E4.BD.BF.E7.94.A8)，[工作负载](#kubernetes-.E5.B7.A5.E4.BD.9C.E8.B4.9F.E8.BD.BD) 和 [节点](#kubernetes-.E8.8A.82.E7.82.B9) 报警模板。

## Kubernetes Master 组件

非托管集群提供如下指标：

| 策略名称 | 策略表达式| 持续时间 | 策略描述
|---------|---------|------|----
| 客户端访问 APIServer 出错 | (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job, cluster_id) / sum(rate(rest_client_requests_total[5m])) by (instance, job, cluster_id))> 0.01 | 15m | 客户端访问 APIServer 出错率大于1%
| 客户端访问 APIServer 证书快过期 | apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (cluster_id, job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400 | 无 | 访问 APIServer 的客户端证书将在24小时后过期
| 聚合 API 出错 | sum by(cluster_id, name, namespace) (increase(aggregator_unavailable_apiservice_count[5m])) > 2 | 无 | 聚合 API 最近5分钟报错
| 聚合 API 可用性低 | (1 - max by(name, namespace, cluster_id)(avg_over_time(aggregator_unavailable_apiservice[5m]))) * 100 < 90 | 5m | 聚合 API 服务最近5分钟可用性低于90%
| APIServer 故障 | absent(sum(up{job="apiserver"}) by (cluster_id) > 0) | 5m | APIServer 从采集目标中消失
| Scheduler 故障 | absent(sum(up{job="kube-scheduler"}) by (cluster_id) > 0) | 15m | Scheduler 从采集目标中消失
| Controller Manager 故障 | absent(sum(up{job="kube-controller-manager"}) by (cluster_id) > 0) | 15m | Controller Manager 从采集目标中消失

## Kubelet

| 策略名称 | 策略表达式| 持续时间 | 策略描述
|---------|---------|------|-------
| Node 状态异常 | kube_node_status_condition{job=\~"\.\*kube-state-metrics",condition="Ready",status="true"} == 0 | 15m | Node 状态异常持续15m
| Node 不可达 | kube_node_spec_taint{job=\~"\.\*kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} == 1 | 15m | Node 不可达，上面的工作负载会重新调度
| Node 上运行太多 pod | count by(cluster_id, node) ((kube_pod_status_phase{job=\~"\.\*kube-state-metrics",phase="Running"} == 1) * on(instance,pod,namespace,cluster_id) group_left(node) topk by(instance,pod,namespace,cluster_id) (1, kube_pod_info{job=\~"\.\*kube-state-metrics"}))/max by(cluster_id, node) (kube_node_status_capacity_pods{job=\~"\.\*kube-state-metrics"} != 1) > 0.95 | 15m | Node 上运行 pod 量快达到上限 
| Node 状态抖动 | sum(changes(kube_node_status_condition{status="true",condition="Ready"}[15m])) by (cluster_id, node) > 2 | 15m | Node 状态在正常和异常之间抖动
| Kubelet 的客户端证书快过期 | kubelet_certificate_manager_client_ttl_seconds < 86400 | 无 | Kubelet 客户端证书将在24小时后过期
| Kubelet 的服务端证书快过期 | kubelet_certificate_manager_server_ttl_seconds < 86400 | 无 | Kubelet 服务端证书将在24小时后过期
| Kubelet 客户端证书续签出错 | increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0 | 15m | Kubelet 续签客户端证书出错
| Kubelet 服务端证书续签出错 | increase(kubelet_server_expiration_renew_errors[5m]) > 0 | 15m | Kubelet 续签服务端证书出错
| PLEG 耗时高 | histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (cluster_id, instance, le) * on(instance, cluster_id) group_left(node) kubelet_node_name{job="kubelet"}) >= 10 | 5m | PLEG 操作耗时的99分位数超过10秒
| Pod 启动耗时高 | histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet"}[5m])) by (cluster_id, instance, le)) * on(cluster_id, instance) group_left(node) kubelet_node_name{job="kubelet"} > 60 | 15m | Pod 启动耗时的99分位数值超过60秒
| Kubelet 故障 | absent(sum(up{job="kubelet"}) by (cluster_id) > 0) | 15m | Kubelet 从采集目标消失

##  Kubernetes 资源使用

| 策略名称 | 策略表达式| 持续时间 | 策略描述
|---------|---------|------|--------
| 集群 CPU 资源过载 | sum by (cluster_id) (max by (cluster_id, namespace, pod, container) (kube_pod_container_resource_requests_cpu_cores{job=\~"\.\*kube-state-metrics"}) * on(cluster_id, namespace, pod) group_left() max by (cluster_id, namespace, pod) (kube_pod_status_phase{phase=~"Pending&#124;Running"} == 1))/sum by (cluster_id) (kube_node_status_allocatable_cpu_cores)>(count by (cluster_id) (kube_node_status_allocatable_cpu_cores)-1) / count by (cluster_id) (kube_node_status_allocatable_cpu_cores) | 5m | 集群内 Pod 申请的 CPU 总量过多，已无法容忍 Node 挂掉
| 集群内存资源过载 | sum by (cluster_id) (max by (cluster_id, namespace, pod, container) (kube_pod_container_resource_requests_memory_bytes{job=\~"\.\*kube-state-metrics"}) * on(cluster_id, namespace, pod) group_left() max by (cluster_id, namespace, pod) (kube_pod_status_phase{phase=~"Pending&#124;Running"} == 1))/sum by (cluster_id) (kube_node_status_allocatable_memory_bytes) > (count by (cluster_id) (kube_node_status_allocatable_memory_bytes)-1) / count by (cluster_id) (kube_node_status_allocatable_memory_bytes) | 5m | 集群内 Pod 申请的内存总量过多，已无法容忍 Node 挂掉
| 集群 CPU 配额过载 | sum by (cluster_id) (kube_resourcequota{job=\~"\.\*kube-state-metrics", type="hard", resource="cpu"})/sum by (cluster_id) (kube_node_status_allocatable_cpu_cores) > 1.5 | 5m | 集群内 CPU 配额超过可分配 CPU 总量
| 集群内存配额过载 | sum by (cluster_id) (kube_resourcequota{job=\~"\.\*kube-state-metrics", type="hard", resource="memory"}) /  sum by (cluster_id) (kube_node_status_allocatable_memory_bytes) > 1.5 | 5m | 集群内内存配额超过可分配内存总量
| 配额资源快使用完 | sum by (cluster_id, namespace, resource) kube_resourcequota{job=\~"\.\*kube-state-metrics", type="used"} / sum by (cluster_id, namespace, resource) (kube_resourcequota{job=\~"\.\*kube-state-metrics", type="hard"} > 0) >= 0.9 | 15m | 配额资源使用率超过90%
| CPU 执行周期受限占比高 | sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (cluster_id, container, pod, namespace) /sum(increase(container_cpu_cfs_periods_total{}[5m])) by (cluster_id, container, pod, namespace) > ( 25 / 100 ) | 15m | CPU 执行周期受到限制的占比高
| Pod 的 CPU 使用率高 |   sum(rate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[1m])) by (cluster_id, namespace, pod, container) / sum(kube_pod_container_resource_limits_cpu_cores) by (cluster_id, namespace, pod, container) > 0.75 | 15m | Pod 的 CPU 使用率超过75%
| Pod 的内存使用率高 | sum(rate(container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!="", container!="POD"}[1m])) by (cluster_id, namespace, pod, container) /sum(kube_pod_container_resource_limits_memory_bytes) by (cluster_id, namespace, pod, container) > 0.75 | 15m | Pod 的内存使用率超高跟75%

##  Kubernetes 工作负载

| 策略名称 | 策略表达式| 持续时间 | 策略描述
|---------|---------|------|--------
| Pod 频繁重启 | increase(kube_pod_container_status_restarts_total{job=\~"\.\*kube-state-metrics"}[5m]) > 0 | 15m | Pod 最近5m频繁重启
| Pod 状态异常 | sum by (namespace, pod, cluster_id) (max by(namespace, pod, cluster_id) (kube_pod_status_phase{job=\~"\.\*kube-state-metrics", phase=~"Pending&#124;Unknown"}) * on(namespace, pod, cluster_id) group_left(owner_kind) topk by(namespace, pod) (1, max by(namespace, pod, owner_kind, cluster_id) (kube_pod_owner{owner_kind!="Job"}))) > 0 | 15m | Pod处于 NotReady 状态超过15分钟
| 容器状态异常 | sum by (namespace, pod, container, cluster_id) (kube_pod_container_status_waiting_reason{job=\~"\.\*kube-state-metrics"}) > 0 | 1h | 容器长时间处于 Waiting 状态
| Deployment 部署版本不匹配| kube_deployment_status_observed_generation{job=\~"\.\*kube-state-metrics"} !=kube_deployment_metadata_generation{job=\~"\.\*kube-state-metrics"} | 15m | 部署版本和设置版本不一致，表示 deployment 变更没有生效
| Deployment 副本数不匹配 | (kube_deployment_spec_replicas{job=\~"\.\*kube-state-metrics"} != kube_deployment_status_replicas_available{job=\~"\.\*kube-state-metrics"}) and (changes(kube_deployment_status_replicas_updated{job=\~"\.\*kube-state-metrics"}[5m]) == 0) | 15m | 实际副本数和设置副本数不一致
| Statefulset 部署版本不匹配 | kube_statefulset_status_observed_generation{job=\~"\.\*kube-state-metrics"} != kube_statefulset_metadata_generation{job=\~"\.\*kube-state-metrics"} | 15m | 部署版本和设置版本不一致，表示 statefulset 变更没有生效
| Statefulset 副本数不匹配 | (kube_statefulset_status_replicas_ready{job=\~"\.\*kube-state-metrics"} != kube_statefulset_status_replicas{job=\~"\.\*kube-state-metrics"}) and ( changes(kube_statefulset_status_replicas_updated{job=\~"\.\*kube-state-metrics"}[5m]) == 0) | 15m | 实际副本数和设置副本数不一致
| Statefulset 更新未生效 | (maxwithout(revision)(kube_statefulset_status_current_revision{job=\~"\.\*kube-state-metrics"}unlesskube_statefulset_status_update_revision{job=\~"\.\*kube-state-metrics"})\*(kube_statefulset_replicas{job=\~"\.\*kube-state-metrics"}!=kube_statefulset_status_replicas_updated{job=\~"\.\*kube-state-metrics"})) and (changes(kube_statefulset_status_replicas_updated{job=\~"\.\*kube-state-metrics"}[5m])==0) | 15m | Statefulset 部分 pod 没有更新
| Daemonset 变更卡住 | ((kube_daemonset_status_current_number_scheduled{job=\~"\.\*kube-state-metrics"}!=kube_daemonset_status_desired_number_scheduled{job=\~"\.\*kube-state-metrics"}) or (kube_daemonset_status_number_misscheduled{job=\~"\.\*kube-state-metrics"}!=0) or (kube_daemonset_updated_number_scheduled{job=\~"\.\*kube-state-metrics"}!=kube_daemonset_status_desired_number_scheduled{job=\~"\.\*kube-state-metrics"}) or (kube_daemonset_status_number_available{job=\~"\.\*kube-state-metrics"}!=kube_daemonset_status_desired_number_scheduled{job=\~"\.\*kube-state-metrics"})) and (changes(kube_daemonset_updated_number_scheduled{job=\~"\.\*kube-state-metrics"}[5m])==0) | 15m | Daemonset 变更超过15分钟
| Daemonset 部分 node 未调度| kube_daemonset_status_desired_number_scheduled{job=\~"\.\*kube-state-metrics"} - kube_daemonset_status_current_number_scheduled{job=\~"\.\*kube-state-metrics"} > 0|10m| Daemonset 在部分 node 未被调度
| Daemonset 部分 node 被错误调度| kube_daemonset_status_number_misscheduled{job=\~"\.\*kube-state-metrics"} > 0 | 15m | Daemonset 被错误调度到一些 node
| Job 运行太久 | kube_job_spec_completions{job=\~"\.\*kube-state-metrics"} - kube_job_status_succeeded{job=\~"\.\*kube-state-metrics"}  > 0 | 12h | Job 执行时间超过12小时
|  Job 执行失败 | kube_job_failed{job=\~"\.\*kube-state-metrics"}  > 0 | 15m | Job 执行失败
| 副本数和 HPA 不匹配 | (kube_hpa_status_desired_replicas{job=\~"\.\*kube-state-metrics"} != kube_hpa_status_current_replicas{job=\~"\.\*kube-state-metrics"}) and changes(kube_hpa_status_current_replicas[15m]) == 0 | 15m | 实际副本数和 HPA 设置的不一致
| 副本数达到 HPA 最大值 |  kube_hpa_status_current_replicas{job=\~"\.\*kube-state-metrics"} == kube_hpa_spec_max_replicas{job=\~"\.\*kube-state-metrics"}| 15m | 实际副本数达到 HPA 配置的最大值
| PersistentVolume 状态异常 | kube_persistentvolume_status_phase{phase=\~"Failed&#124;Pending",job=\~"\.\*kube-state-metrics"} > 0 | 15m | PersistentVolume 处于 Failed 或 Pending状态

##  Kubernetes 节点

| 策略名称 | 策略表达式| 持续时间 | 策略描述
|---------|---------|------|--------
| 文件系统空间快耗尽 | (node_filesystem_avail_bytes{job="node-exporter",fstype!=""}/node_filesystem_size_bytes{job="node-exporter",fstype!=""}\*100<15 and predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h],4\*60\*60)<0 and node_filesystem_readonly{job="node-exporter",fstype!=""}==0) | 1h | 文件系统空间预计在4小时后使用完
| 文件系统空间使用率高 | (node_filesystem_avail_bytes{job="node-exporter",fstype!=""}/node_filesystem_size_bytes{job="node-exporter",fstype!=""}\*100<5 and node_filesystem_readonly{job="node-exporter",fstype!=""}==0) | 1h | 文件系统可用空间低于5%
| 文件系统inode快耗尽 | (node_filesystem_files_free{job="node-exporter",fstype!=""}/node_filesystem_files{job="node-exporter",fstype!=""}\*100<20 and predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h],4\*60\*60)<0 and node_filesystem_readonly{job="node-exporter",fstype!=""}==0) | 1h | 文件系统 inode 预计在4小时后使用完
| 文件系统inode使用率高 | (node_filesystem_files_free{job="node-exporter",fstype!=""}/node_filesystem_files{job="node-exporter",fstype!=""}*100<3 and node_filesystem_readonly{job="node-exporter",fstype!=""}==0) | 1h | 文件系统可用 inode 低于3%
| 网卡状态不稳定 | changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) | 2m | 网卡状态不稳定，在  up 和 down 间频繁变化
| 网卡接收出错 | increase(node_network_receive_errs_total[2m]) > 10 | 1h | 网卡接收数据出错
| 网卡发送出错 | increase(node_network_transmit_errs_total[2m]) > 10 | 1h | 网卡发送数据出错
| 机器时钟未同步 | min_over_time(node_timex_sync_status[5m]) == 0 | 10m | 机器时间最近未同步，检查 NTP 是否正常配置
| 机器时钟漂移 | (node_timex_offset_seconds>0.05 and deriv(node_timex_offset_seconds[5m])>=0) or (node_timex_offset_seconds<-0.05 and deriv(node_timex_offset_seconds[5m])<=0) | 10m |机器时间漂移超过300秒，检查 NTP 是否正常配置

