# 函数部署

### 步骤一 环境准备

在开始部署云函数前，您需要：
1. 确保已经在您自身的电脑上安装好 Python2.7 环境和 Pip 工具。
> **您也可以直接通过下载示例代码的压缩包，而略去环境搭建和本机代码编写工作，**[**点我下载**](https://main.qcloudimg.com/raw/498f2eaf73fdd65665ae865e20a9e6b4.zip)。

2. 获取您自身账号的 SecretId 和 SecretKey,在云函数中调用 COS 的 SDK 接口时需要用到。您可以在 [**云 API 密钥控制台**](https://console.cloud.tencent.com/cam/capi) 中查看对应信息。如下图所示：
![](https://main.qcloudimg.com/raw/78242580d3d1949cd15ac6be83e84d01.png)

3. 前往[**对象存储 COS 的控制台**](https://console.cloud.tencent.com/cos5/bucket)，创建一个 bucket，用于存放云函数处理后的 Ckafca 消息。

4. 前往 [**Ckafka 控制台**](https://console.cloud.tencent.com/ckafka?rid=1)，确保已经购买 Ckafca 实例，并创建好 Topic。

### 步骤二 创建云函数 Ckafka_SCF_COS
1. 首先在本地创建需要放置函数代码的文件夹，并通过命令行进入该目录下，直接执行 Pip 命令安装 pytz 库：
```
pip install pytz -t .
```
2. 在函数代码文件夹的根目录下，使用下面的示例代码创建 Python 文件，可以命名为：Ckafka_SCF_COS.py。
```
# -*- coding: utf-8 -*-
import os
import logging
import datetime
import random
import pytz
from qcloud_cos_v5 import CosConfig
from qcloud_cos_v5 import CosS3Client
from qcloud_cos_v5 import CosServiceError
from qcloud_cos_v5 import CosClientError

# 设置用户属性, 包括secret_id, secret_key, region，bucket
appid = '1251762227'  # 请替换为您的 APPID
secret_id = u'*********'  # 请替换为您的 SecretId
secret_key = u'********'  # 请替换为您的 SecretKey
region = 'ap-guangzhou'  # 替换为用户的region
token = ''  # 使用临时秘钥需要传入Token，默认为空,可不填
bucket_upload = "mason-ckafka-scf-cos-1251762227"  # 替换为需要写入的COS Bucket

# 获取配置对象
config = CosConfig(Region=region, Secret_id=secret_id, Secret_key=secret_key, Token=token)
client = CosS3Client(config)
logger = logging.getLogger()

# 生成写入文件名
def object_key_generater():
    logger.info("start to generate key name")
    tz = pytz.timezone('Asia/Shanghai')
    time = datetime.datetime.now(tz).strftime("%Y-%m-%d-%H:%M:%S")
    random_name = random.randint(1, 200)
    dir_name = datetime.datetime.now(tz).strftime("%Y-%m-%d-%H")
    file_name = format(time) + '-' + str(random_name) +'.txt'
    object_key = '{}/{}'.format( dir_name,file_name)
    return object_key

# 检查文件是否已存在
def check_cos_file(key):
    try:
        resp = client.head_object(
            Bucket=bucket_upload,
            Key=key
        )
        logger.info("check_cos_file of resp is [%s]"% resp)
        return True
    except CosServiceError, e:
        # print("head error")
        # if e['code'] == "NoSuchResource":
        logger.info("e is [%s]"% e)
        if e.get_error_code()== "NoSuchResource":
            logger.info("check_cos_file is [%s]"% e.get_error_code())
            return False

#删除本地文件
def delete_local_file(src):
    logger.info("delete files and folders")
    if os.path.isfile(src):
        try:
            os.remove(src)
        except:
            pass
    elif os.path.isdir(src):
        for item in os.listdir(src):
            itemsrc = os.path.join(src, item)
            delete_local_file(itemsrc)
        try:
            os.rmdir(src)
        except:
            pass

#上传文件到COS
def upload_loacal_file(loacalpath):
    logger.info("Start to upload")
    if os.path.isfile(loacalpath):
        logger.info("local_filename is [%s]" % loacalpath)
        key = object_key_generater()
        while check_cos_file(key) == True:
            key = object_key_generater()
        logger.info("cos_object_name is [%s]" % key)
        response = client.put_object_from_local_file(
            Bucket=bucket_upload,
            LocalFilePath=loacalpath,
            Key=key)
        logger.info("upload result is [%s]" % response)
        delete_local_file(str(loacalpath))
        return True
    else:
        logger.info("Upload fail")
        return False

def main_handler(event, context):
    logger.info("start main handler")
    local_path = '/tmp/local_file.txt'
    data = ""
    with open(local_path, "a") as f:
        for record in event['Records']:
            if 'Ckafka' not in record.keys():
                continue
            data = record['Ckafka']['msgBody'].decode("unicode-escape")
            # logger.info("data is [%s]" % data)
            f.write(data)
            f.write('\r\n')
    if upload_loacal_file(local_path) == True:
        return "write success"
    else:
        return "write fail"

```
3. Python 文件保存后，回到根目录下，对所有文件进行打包（**请注意，不是对外层的文件夹打包**）；另外还需要保证: **Ckafka_SCF_COS.py 存在于根目录下，压缩包需要为 zip 格式**。
> **注意：**
您可以直接使用步骤一中下载好的 zip 包，而略去步骤 1 和步骤 2。

4. 前往[无服务器云函数 SCF 的控制台](https://console.cloud.tencent.com/scf/list?rid=4)，选择地域“广州”，单击新建函数，选择空白函数模板，命名函数为 Ckafka_SCF_COS，运行环境默认为 Python2.7，单击“完成”。
然后在【函数代码】的编辑框中，选择本地上传zip包，选中打好的zip包后，**修改“执行方法”为：Ckafka_SCF_COS.main_handler**，再单击保存。如下图所示：
![](https://main.qcloudimg.com/raw/30a47380d8a412286bc4819c5217d8a6.png)
> **注意：**
保存完代码包后，需要在【函数代码】框中，把 appid、secret_id、secret_key 和 bucket_upload 替换为您自己的 APPID、SecretId、SecretKey 和 bucket 名方能使用。修改完后，记得单击“保存”。如下图所示：
![](https://main.qcloudimg.com/raw/72f03a350b6327473ce14146994ca6c6.png)


### 步骤三 配置 Ckafca 触发器

单击【触发方式】功能栏，选择“添加触发方式”，然后选中“Ckafca触发”，选择需要对接的 Ckafca 实例和 Topic。最大批量消息数是单次触发云函数运行时最大可处理的消息条数，比如配置500，则最多会有500条消息会触发一次云函数。当 Ckafca 生产的消息过多时，消费组会自动触发多个函数实例运行，加速消息消费速度。这里需要根据单条消息的大小和实际业务量进行配置，默认消息总数的大小要小于 1 MB。
![](https://main.qcloudimg.com/raw/6b7d486e0fe4d3b23b7c2a7bd5a4a5a6.png)