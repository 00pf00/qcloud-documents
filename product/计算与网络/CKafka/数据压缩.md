## 压缩的目的

数据压缩可以减少网络 IO 传输量，减少磁盘存储空间。

## 消息格式
目前 Kafka 共有两类消息格式，社区分别称之为V1版本和V2版本（在0.11.0.0引入）。目前 CKafka 支持0.9、0.10.2开源版本，独占集群支持1.1.1版本。

**不同版本对应不同的配置**，说明如下：
- 消息格式转换主要是为了兼容老版本的消费者程序，在一个Kafka集群中通常同时保存多种版本的消息格式（V1/V2）。
o Broker端会对新版本消息执行向老版本格式的转换，该过程中会涉及消息的解压缩和重新压缩
- 消息格式转换对性能的影响很大，除了增加额外的压缩和解压缩操作之外，还会让 Kafka 丧失引以为傲的 Zero Copy 特性。因此，**一定要保证消息格式的统一**。
o Zero Copy：数据在磁盘和网络进行传输时，避免昂贵的内核态数据拷贝，从而实现快速的数据传输。



## 压缩配置

#### 生产者
```
Properties props = new Properties();

props.put("bootstrap.servers", "localhost:9092");

props.put("acks", "all");

props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");

props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

// 开启GZIP压缩

// Producer启动后，生产的每个消息集合都会经过压缩，能够很好地节省网络传输带宽和Kafka Broker端的磁盘占用

// 压缩格式配置，目前 0.9(包含)以下版本不允许使用压缩，0.10（包含）以上不允许使用 GZip 压缩

props.put("compression.type", " lz4 ");

Producer<String, String> producer = new KafkaProducer<>(props);

大部分情况下，Broker从Producer接收到消息后，仅仅只是原封不动地保存，而不会对其进行任何修改
```

## 压缩算法对比
Kafka 2.1.0之前，Kafka支持三种压缩算法：GZIP、Snappy、LZ4。

评估一个压缩算法的优劣，主要有两个指标：压缩比、压缩/解压缩吞吐量。

LZ4具有最高的吞吐量，在Kafka的实际使用中

吞吐量：LZ4 > Snappy > GZIP

压缩比：LZ4 > GZIP > Snappy

物理资源

带宽：由于Snappy的压缩比最低，因此占用的网络带宽最大

CPU：各个压缩算法差不多，在压缩时Snappy使用更多的CPU，在解压缩时GZIP使用更多的CPU

带宽资源比CPU资源和磁盘资源更吃紧（千兆网络是标配），首先排除Snappy，其次排除GZIP，剩下在LZ4

## 注意事项

- 发送数据到 ckafka，不能设置压缩compression.codec
- 使用Gzip导致所有的消息都是InValid消息
由于 Gzip 压缩对于 CPU 的消耗较高，CKafka不支持Gzip压缩格式
- 使用lz4则会导致程序直接core
可能由于消息格式错误导致的，CKafka默认版本为0.10.2，所以使用的消息格式应为V1版本。
- 如何设置消息格式的版本
不同Kafka Client的SDK设置方式不同，可于开源社区进行查询，例如 [C/C++ Client 的说明](https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#compression)。
