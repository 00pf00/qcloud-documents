该系列文档介绍如何在云服务器中， 使用 Intel<sup>®</sup> Xeon<sup>®</sup> 可扩展处理器进行机器学习及深度学习相关任务。

## 具备优势
使用 Intel<sup>®</sup> Xeon<sup>®</sup> 可扩展处理器运行机器学习或深度学习工作负载时，具备以下优势：
- 适合处理大内存型工作负载、医学成像、GAN、地震分析、基因测序等场景中使用的 3D-CNN 拓扑。
- 支持使用简单的 `numactl` 命令进行灵活的核心控制，也适用小批量的实时推理。
- 强大的生态系统支持，可直接在大型集群上进行分布式训练，避免额外添加大容量存储和昂贵的缓存机制来进行规模化架构的训练。
- 可在同一个集群中支持多种工作负载（例如 HPC、BigData、AI 等），获取更优的 TCO。
- 通过 SIMD 加速，满足众多实际深度学习应用程序的计算要求。
- 同一套基础架构可直接用于训练及推理。

## 选型推荐
云服务器的多种实例规格可用于多种应用开发，其中 [标准型 S5](https://cloud.tencent.com/document/product/213/11518#S5) 及 [内存型 M5](https://cloud.tencent.com/document/product/213/11518#M5) 适用于机器学习或深度学习。这些实例配备了第二代 Intel<sup>®</sup> Xeon<sup>®</sup> 处理器，适配 Intel<sup>®</sup> DL boost 学习能力。推荐配置如下表：
<table>
<tr>
<th>平台类型</th><th>实例规格</th>
</tr>
<tr>
<td>深度学习训练平台</td>
<td> 84vCPU 的标准型 S5 实例或 48vCPU 的内存型 M5 实例。</td>
</tr>
<tr>
<td>深度学习推理平台</td>
<td>8/16/24/32/48vCPU 的标准型 S5 实例或内存型 M5 实例。 </td>
</tr>
<tr>
<td>机器学习训练或推理平台</td>
<td>48vCPU 的标准型 S5 实例或 24vCPU 的内存型 M5 实例。</td>
</tr>
</table>
 
## 部署流程
典型的深度学习应用程序开发及部署流程如下图所示：
![](https://main.qcloudimg.com/raw/d30b9fd09d30edb22c780cabb12a1e5a.png)
