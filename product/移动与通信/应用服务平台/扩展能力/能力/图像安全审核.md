图像安全审核提供鉴黄、鉴政、鉴暴恐等多种类型的敏感内容审核服务，有效识别违禁图片，规避违规风险。

## 扩展工作模式
当你使用这个扩展时：
1.上传图像到云存储；
2.按照需要获取图像处理结果；
3.扩展能力帮你处理图像，并返回结果；

### 前置要求
已经开通云开发。
### 扩展配置信息
你可以通过以下配置参数：

- 环境ID：选择要部署的环境，在哪个环境下使用

### 计费
此扩展使用云开发或其他腾讯云服务，可能会产生相关费用：

- 数据万象（[产品定价](https://buy.cloud.tencent.com/price/ci)及[使用明细](https://console.cloud.tencent.com/ci/stat/pictureStat)）
- 云存储（[产品定价](https://buy.cloud.tencent.com/price/tcb)及[使用明细](https://console.cloud.tencent.com/tcb)）
- 云函数（[产品定价](https://buy.cloud.tencent.com/price/tcb)及[使用明细](https://console.cloud.tencent.com/tcb)）

当你使用云开发扩展时，你只需要为你使用的云资源付费；云开发与云上其他资源分开计费，你可以在[费用中心](https://console.cloud.tencent.com/expense/bill/overview)查看具体信息。

### 启用的API和创建的资源
-  __Type:__  数据万象
 __Description:__  为开发者提供图片、视频等多种数据的智能处理服务。
-  __Type:__  Cloud Storage
 __Description:__  存储图片，并通过CDN提升图片加载速度。
-  __Type:__  Cloud Function
 __Description:__  检测图像处理参数并为图像处理生成签名，保证操作的合法性。
## 怎么安装扩展

### 使用云开发控制台
你可以通过云开发控制台，来安装和管理扩展。

## 怎么使用扩展

>!注意：
- 如果您在 web 网站使用该扩展，请先在云开发控制台将网站域名添加为当前环境的安全域名。

#### 1.安装扩展SDK到项目
```
npm install --save @cloudbase/extension@latest
```
#### 2.调用扩展SDK
**调用参数**
|名称	|类型	|是否必须	|说明|
|--| -- | -- | -- |
|action	|String	|是	|操作类型，传：ImageProcess|
|cloudPath|	String|	是|	文件的绝对路径，与tcb.uploadFile中一致|
|operations	|Object	|是	|处理参数。审核类型支持：porn（涉黄识别）、terrorist（涉暴恐识别）、politics（涉政识别）、ads（广告识别），可选择多种识别类型，如porn,ads |

**调用示例**

```javascript
const extCi = require("@cloudbase/extension-ci");
//-------客户端使用--------//
const tcb = require("tcb-js-sdk");

//-------云函数中--------//
const tcb = require("@cloudbase/node-sdk");

tcb.init({
  env: "你的环境ID"
});

tcb.registerExtension(extCi);

async function demo() {
  try {
    const opts = {
      type: "porn" // 审核类型：porn（涉黄识别）、terrorist（涉暴恐识别）、politics（涉政识别）、ads（广告识别），可选择多种识别类型，如porn,ads
    }
    const res = await tcb.invokeExtension('CloudInfinite',{
      action:'DetectType',
      cloudPath: "ab.png", // 需要分析的图像的绝对路径，与tcb.uploadFile中一致
      operations: opts
    })
    console.log(JSON.stringify(res, null, 4));
    /*
    res.data = {
      RecognitionResult: {
        // porn对应PornInfo；terrorist对应TerroristInfo；politics对应PoliticsInfo；ads对应AdsInfo，以下以PornInfo为例
        PornInfo: {
          Code: 0,
          HitFlag: 0, //是否命中：0(未命中)，1(命中)，2(疑似)
          Score: 30, // 审核分值：0 - 60分(正常)，60 - 90分(疑似敏感)，90 - 100分(确定敏感)
          Label: "xxx" // 识别出的图片标签
        }
      }
    }
    */
  } catch (err) {
    console.log(JSON.stringify(err, null, 4));
  }
}
```