Word2Vec

* **算法说明**  
  Word2Vec (Word to Vector) 由谷歌Mikolov提出，通过将词映射至连续的向量空间，克服擦表达的稀疏性，进而有效地表达词汇，度量语义关系。TI-ONE平台提供了基于 Skip-gram 的词向量模型，编码好的词向量可用于其他NLP场景。

* **训练节点**
  - 数据形式
    - 数据形式：TextTrainData 
  - 算法IO参数
    - 训练集输入：训练数据输入路径，必须为ceph文件系统上的路径名。
    - 验证集输入：验证数据输入路径，每行数据为四个词，做类比推理验证，没有验证集可不填。必须为ceph文件系统上的路径名。
    - 模型输出：模型输出路径，也就是checkpoint路径，必须为ceph文件系统上的路径名，如/cephfs/person/rtx/word2vec/model
    - 可视化输出：可视化信息输出路径，即summary输出路径，必须为ceph文件系统上的路径名，如/cephfs/person/rtx/word2vec/summary
  - 算法参数
    - 词向量维度：指定最终词向量的维度
    - 梯度更新batch大小：每次梯度更新时用的batch大小，即一次训练输入多少个样本
    - 初始学习步长：初始学习步长，随着迭代的进行，会逐渐减小
    - 训练次数：训练数据的次数，在机器学习领域一般称之为epoch次数
    - 负采样个数：负采样的个数，为公式3中k的大小
    - 二次采样t：高频二次采样参数，为公式5中t的大小
    - 最小词频：词频低于该值得词表示为陌生词，过滤该类词，不将其加入语料库词典
    - 上下文窗口大小：Skip-gram提取样本时指定的上下文大小，即一个词与前后多少个词有关
    - 训练线程数：指定训练时的线程数
    - 可视化时间间隔(s)：每隔多少秒输出一次summary信息
    - 模型时间间隔(s)：每隔多少秒对模型做一次checkpoint
    
    分词

算法说明

分词，即将中文句子划分成词语，词语之间用空格分隔。

参数设置

输入参数

- 输入数据：未分词的中文文本，每行为一个句子。

输出参数

- 输出数据：分词后的中文文本，每行为一个句子，词与词之间用空格分隔。

算法参数

- 标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行分词。
  实例生成

1. 使用数据节点，上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到分词节点，配置好输出数据路径和标签分隔符，点击【运行】开始分词。



去除停用词

算法说明

去除文本中的停用词，文本需要预先分词。

参数设置

输入参数

- 输入数据：分词后的中文文本，每行为一个句子，词语之间用空格分隔。
- 停用词表：要去除的停用词列表，每行为一个词。

输出参数

- 输出数据：去除停用词后的中文文本，每行为一个句子。

算法参数

- 标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行去停用词。

实例生成

1. 使用数据节点，上传输入数据和停用词表数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到去停用词词节点，配置好输出数据路径和标签分隔符，点击【运行】开始去停用词。



LSTM文本分类

算法说明

LSTM文本分类算法首先使用双向LSTM网络（论文链接：http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.676.4320&rep=rep1&type=pdf）产生要分类的句子的向量表示，再通过全连接层网络对句子进行分类。

参数设置

输入参数

- 训练数据：每一行为一个句子，词与词之间用空格分隔，句子和标签之间用特定分隔符分隔（分隔符在算法参数中可以设置）
- 验证数据：格式同训练数据。
- logs存储路径：存储events文件的路径，可以从该路径启动tensorboard。

算法参数

- 分隔符：用于分隔句子和标签的分隔符
- 词向量维度：网络中词向量的维度。
- LSTM维度：网络中句子的向量表示的维度。
- 批处理大小：即训练的batch_size。
- 训练epoch数：训练数据的训练次数。
- 学习率：即learning_rate。
- 是否使用预训练好的词向量：如设为True，可填写词向量文件路径。词向量文件格式与glove词向量官方格式相同。（注意：如果使用预训练好的词向量，预训练词向量的维度应等于参数【词向量维度】的值）
  实例生成

1. 使用数据节点，上传数据，数据格式见上文【训练数据】部分。
2. （可选）如数据只有一份，可以使用【输入】-【数据转换】中的【NLP数据切分】节点，将上传的数据按比例分为训练数据和验证数据。
3. 将两份数据分别连接到LSTM-classifier节点的两个输入桩。点击【运行】开始训练。



Fasttext

算法说明

Fasttext是一种简单有效的句子分类算法， 通过词向量以及ngram向量的平均值计算出句子的向量表示，再通过全连接层网络对句子进行分类。论文链接（https://arxiv.org/pdf/1607.01759.pdf）

参数设置

输入参数

- 训练数据：每一行为一个句子，词与词之间用空格分隔，句子和标签之间用特定分隔符分隔（分隔符在算法参数中可以设置）
- 验证数据：格式同训练数据。
- logs存储路径：存储events文件的路径，可以从该路径启动tensorboard。

算法参数

- 分隔符：用于分隔句子和标签的分隔符
- 词向量维度：网络中词向量的维度。
- 批处理大小：即训练的batch_size。
- 训练epoch数：训练数据的训练次数。
- 学习率：即learning_rate。
- 是否使用预训练好的词向量：如设为True，可填写词向量文件路径。词向量文件格式与glove词向量官方格式相同。（注意：如果使用预训练好的词向量，预训练词向量的维度应等于参数【词向量维度】的值）
- 是否使用ngrams：如设为True，在计算句子向量表示时将引入ngrams以建模词序信息。需要配置使用的n值，ngrams进行hash后的bucket数和ngram向量表示的维度。

实例生成

1. 使用数据节点，上传数据，数据格式见上文【训练数据】部分。
2. （可选）如数据只有一份，可以使用【输入】-【数据转换】中的【NLP数据切分】节点，将上传的数据按比例分为训练数据和验证数据。
3. 将两份数据分别连接到Fasttext节点的两个输入桩。点击【运行】开始训练。



TextCNN

算法说明

TextCNN使用卷积神经网络产生句子的向量表示，再通过全连接层网络对句子进行分类。论文链接（https://arxiv.org/pdf/1408.5882.pdf）

参数设置

输入参数

- 训练数据：每一行为一个句子，词与词之间用空格分隔，句子和标签之间用特定分隔符分隔（分隔符在算法参数中可以设置）
- 验证数据：格式同训练数据。
- logs存储路径：存储events文件的路径，可以从该路径启动tensorboard。

算法参数

- 分隔符：用于分隔句子和标签的分隔符
- 词向量维度：网络中词向量的维度。
- 各层网络卷积核大小：即kernel_size。
- 各层网络卷积核个数：即通道数
- 批处理大小：即训练的batch_size。
- 训练epoch数：训练数据的训练次数。
- 学习率：即learning_rate。
- 是否使用预训练好的词向量：如设为True，可填写词向量文件路径。词向量文件格式与glove词向量官方格式相同。（注意：如果使用预训练好的词向量，预训练词向量的维度应等于参数【词向量维度】的值）

实例生成

1. 使用数据节点，上传数据，数据格式见上文【训练数据】部分。
2. （可选）如数据只有一份，可以使用【输入】-【数据转换】中的【NLP数据切分】节点，将上传的数据按比例分为训练数据和验证数据。
3. 将两份数据分别连接到TextCNN节点的两个输入桩。点击【运行】开始训练。



BiLSTM+CRF

算法说明

BiLSTM+CRF是一种常用的序列标注模型，能用于分词，词性标注，命名实体识别等序列标注任务。模型使用双向LSTM网络产生句子中的各个词语的向量表示，并据此计算词语标签的概率分布。然后，使用CRF计算总概率最大的标签序列。论文链接：（https://arxiv.org/pdf/1508.01991.pdf）

参数设置

输入参数

- 训练数据：文本文件，其中每一行是一个句子及其各个词语的对应标签，句子和标签之间由特定分隔符分隔（默认为__label__)，句子中的各个词语之间，以及各个标签之间用空格分隔。由于算法对句子中的每个词语进行标注，词语个数必须等于标签个数。如：
  	词语1 词语2 词语3__label__标签1 标签2 标签3
- 验证数据：文本文件，格式与训练数据相同。
- 批处理大小：即算法batch_size。
- 学习率：即算法的learning_rate。
- 训练次数：即将训练数据训练的epoch数。
- 词向量维度：即每个词语向量表示的维度。
- LSTM维度：即每个词语LSTM向量表示的维度。
- 使用预训练好的词向量模型：如设为True，可填写词向量文件路径。词向量文件格式与glove词向量官方格式相同。（注意：如果使用预训练好的词向量，预训练词向量的维度应等于参数【词向量维度】的值）

输出参数

- 日志目录：即存放events文件目录的路径，可以用此路径启动tensorboard查看训练情况。
  实例生成

1. 使用数据节点，上传数据，数据格式见上文【训练数据】部分。
2. （可选）如数据只有一份，可以使用【输入】-【数据转换】中的【NLP数据切分】节点，将上传的数据按比例分为训练数据和验证数据。
3. 将两份数据分别连接到BiLSTM-CRF节点的两个输入桩。点击【运行】开始训练。



基于PMI和熵的新词发现

算法说明

PMI（点互信息）和左右熵能够刻画一个文本片段的凝固程度和灵活运用程度，因此可以用于发现文本中不存在词库中的新词。

参数设置

输入参数

- 输入数据：未分词的中文纯文本文件。
- 词库：（可选）文本文件，每行为一个词。如发现的新词已经存在这个词库中，则跳过这一新词。

输出参数

- 输出数据：算法发现的新词，每行为一个词。

算法参数

- 最大词语长度：只考虑长度不超过这一长度的文本片段构成新词的可能性。
- 保留前n个新词：只保留可能性最大的前若干个新词。

实例生成

1. 使用数据节点，上传数据，数据格式见上文【训练数据】部分
2. 将数据连接到【新词发现】节点的输入桩，设置好输出数据路径，点击【运行】开始发现新词。



Word2Vec

算法说明

Word2Vec是一种经典的词向量算法，能够从大量文本中学习出各个词语的向量表示。这一向量表示可以用作其它深度学习模型的初始值。论文链接（https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf）

参数设置

输入参数

- 训练数据：文本文件，词语之间使用空格分隔。
- 验证数据：（可选）包含四元组的数据集，如word2vec官方questions-words.txt，用于评价生成的词向量的质量。

输出参数

- 保存路径：生成的词向量文件的保存路径。生成的文件为文本文件，每行为一个词语及其向量表示，词语和向量之间，向量中的各个数字之间使用空格分隔。

算法参数

- 词向量维度：要训练的词向量维度。
- 窗口大小：skip-gram算法中的window_size参数。
- 最小出现次数：只训练出现次数大于这一次数的词语的词向量。
- 训练epoch数：训练数据的训练次数。
- 学习率：即learning_rate参数。
- 批处理大小：即训练的batch_size。
- 负采样个数：skip-gram算法中的负样本个数。

实例生成

1. 使用数据节点，上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到word2vec节点，配置好保存路径，点击【运行】按钮开始训练。



Glove

算法说明

Glove是一种经典的词向量算法，能够从大量文本中学习出各个词语的向量表示。这一向量表示可以用作其它深度学习模型的初始值。论文链接（http://www.aclweb.org/anthology/D14-1162）

参数设置

输入参数

- 训练数据：文本文件，词语之间使用空格分隔。
- 验证数据：（可选）包含四元组的数据集，如word2vec官方questions-words.txt，用于评价生成的词向量的质量。

输出参数

- 保存路径：生成的词向量文件的保存路径。生成的文件为文本文件，每行为一个词语及其向量表示，词语和向量之间，向量中的各个数字之间使用空格分隔。

算法参数

- 词向量维度：要训练的词向量维度。
- 窗口大小：计算共现矩阵时使用的window_size参数。
- 最小出现次数：只训练出现次数大于这一次数的词语的词向量。
- 训练epoch数：训练数据的训练次数。
- 学习率：即learning_rate参数。
- 批处理大小：即训练的batch_size。
- 最大词汇表大小：如果训练数据中单词总数超过这一大小n，只训练出现频率最高的n个词的词向量。

实例生成

1. 使用数据节点，上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到glove节点，配置好保存路径，点击【运行】按钮开始训练。



Sentence2Vec

算法说明

Sentence2Vec可以将句子转换为向量表示，转换方法有三种：1.转换为词向量平均值；2.转换为词向量加权平均值，权重由词频决定，词频越高，权重越低；3.使用论文A simple but tough-to-beat baseline for sentence embeddings的方法进行转换。论文链接（https://openreview.net/pdf?id=SyK00v5xx）

参数设置

输入参数

- 输入数据：文本文件，每一行为一个句子，词语之间使用空格分隔。

输出参数

- 输出数据：文本文件，每一行为输入数据对应行的句子的向量表示，数字之间用空格分隔。

算法参数

- 预训练词向量：文本文件，格式见word2vec和glove算法的【输出参数】部分。
- 转换方式：三选一，average对应词向量平均值；weighted_average对应词向量加权平均值；svd对应论文中的方法。

实例生成

1. 使用数据节点，上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到sentence2vec节点，配置好预训练词向量路径和转换方式，点击【运行】按钮开始训练。

