### 样例 Cube 快速入门

- ##### 运行脚本； 重启 Kylin 服务器刷新缓存;

```
/usr/local/service/kylin/bin/sample.sh
```

- ##### 用默认的用户名和密码 ADMIN/KYLIN 登陆 Kylin 网站，选择 project 下拉框（左上角）中的 *learn_kylin* 工程;

- ##### 选择名为 kylin_sales_cube 的样例 Cube，点击 “Actions” -> “Build”，选择一个在 2014-01-01 之后的日期（覆盖所有的 10000 样例记录);

 ![](https://main.qcloudimg.com/raw/65ef171990d4323da02379971a69a9b4.png)

- ##### 点击 “Monitor” 标签，查看 build 进度直至 100%;

  ![](https://main.qcloudimg.com/raw/7cc45f02f5dbb10deee82b6e52399349.png)

- ##### 点击 “Insight” 标签，执行 SQLs，例如

```
select part_dt, sum(price) as total_sold, count(distinct seller_id) as sellers from kylin_sales group by part_dt order by part_dt

```

![](https://main.qcloudimg.com/raw/21cc4fc69424d3ad19b42b3d6373204f.png)

### 用 Spark 构建 Cube

- ##### 准备 “kylin.env.hadoop-conf-dir”

  在 kylin.properties 中设置属性 

```
kylin.env.hadoop-conf-dir=/usr/local/service/hadoop/etc/hadoop
```

- ##### 检查 Spark 配置

  Kylin 在 $KYLIN_HOME/spark 中嵌入一个 Spark binary (v2.1.2)，所有使用 “kylin.engine.spark-conf.” 作为前缀的 Spark 配置属性都能在 $KYLIN_HOME/conf/kylin.properties 中进行管理。这些属性当运行提交 Spark job 时会被提取并应用；例如，如果您配置 “kylin.engine.spark-conf.spark.executor.memory=4G”，Kylin 将会在执行 “spark-submit” 操作时使用 “–conf spark.executor.memory=4G” 作为参数。

运行 Spark cubing 前，建议查看一下这些配置并根据您集群的情况进行自定义。下面是建议配置，开启了 Spark 动态资源分配:

```
kylin.engine.spark-conf.spark.master=yarn
kylin.engine.spark-conf.spark.submit.deployMode=cluster
kylin.engine.spark-conf.spark.dynamicAllocation.enabled=true
kylin.engine.spark-conf.spark.dynamicAllocation.minExecutors=1
kylin.engine.spark-conf.spark.dynamicAllocation.maxExecutors=1000
kylin.engine.spark-conf.spark.dynamicAllocation.executorIdleTimeout=300
kylin.engine.spark-conf.spark.yarn.queue=default
kylin.engine.spark-conf.spark.driver.memory=2G
kylin.engine.spark-conf.spark.executor.memory=4G
kylin.engine.spark-conf.spark.yarn.executor.memoryOverhead=1024
kylin.engine.spark-conf.spark.executor.cores=1
kylin.engine.spark-conf.spark.network.timeout=600
kylin.engine.spark-conf.spark.shuffle.service.enabled=true
#kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.eventLog.enabled=true
kylin.engine.spark-conf.spark.hadoop.dfs.replication=2
kylin.engine.spark-conf.spark.hadoop.mapreduce.output.fileoutputformat.compress=true
kylin.engine.spark-conf.spark.hadoop.mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
kylin.engine.spark-conf.spark.io.compression.codec=org.apache.spark.io.SnappyCompressionCodec
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///kylin/spark-history
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///kylin/spark-history


## uncomment for HDP
#kylin.engine.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current
#kylin.engine.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
#kylin.engine.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current
```

为了在 Hortonworks 平台上运行，需要将 “hdp.version” 指定为 Yarn 容器的 Java 选项，因此请取消 kylin.properties 的最后三行的注释。

除此之外，为了避免重复上传 Spark jar 包到 Yarn，您可以手动上传一次，然后配置 jar 包的 HDFS 路径；请注意，HDFS 路径必须是全路径名。

```
jar cv0f spark-libs.jar -C $KYLIN_HOME/spark/jars/ .
hadoop fs -mkdir -p /kylin/spark/
hadoop fs -put spark-libs.jar /kylin/spark/
```

然后，要在 kylin.properties 中进行如下配置:

```
kylin.engine.spark-conf.spark.yarn.archive=hdfs://sandbox.hortonworks.com:8020/kylin/spark/spark-libs.jar
```

所有 “kylin.engine.spark-conf.*” 参数都可以在 Cube 或 Project 级别进行重写，这为用户提供了灵活性。

- ##### 创建和修改样例 cube

  运行 sample.sh 创建样例 cube，然后启动 Kylin 服务器:

```
/usr/local/service/kylin/bin/sample.sh
/usr/local/service/kylin/bin/kylin.sh start
```

Kylin 启动后，访问 Kylin 网站，在 “Advanced Setting” 页，编辑名为 “kylin_sales” 的 cube，将 “Cube Engine” 由 “MapReduce” 换成 “Spark”:

![](https://main.qcloudimg.com/raw/421aa226fc0cf1e4a282a72908cceca0.png)
点击 “Next” 进入 “Configuration Overwrites” 页面，点击 “+Property” 添加属性 “kylin.engine.spark.rdd-partition-cut-mb” 其值为 “500” (理由如下):

![](https://main.qcloudimg.com/raw/e58ca942eaa655bcbc2aaa11ad22c52a.png)

样例 cube 有两个耗尽内存的度量: “COUNT DISTINCT” 和 “TOPN(100)”；当源数据较小时，他们的大小估计的不太准确: 预估的大小会比真实的大很多，导致了更多的 RDD partitions 被切分，使得 build 的速度降低。500 对于其是一个较为合理的数字。点击 “Next” 和 “Save” 保存 cube。

对于没有”COUNT DISTINCT” 和 “TOPN” 的 cube，请保留默认配置。

- ##### 用 Spark 构建 Cube

点击 “Build”，选择当前日期为 end date。Kylin 会在 “Monitor” 页生成一个构建 job，第 7 步是 Spark cubing。Job engine 开始按照顺序执行每一步。
![](https://main.qcloudimg.com/raw/170a244544029dd0f8797c863971aacb.png)


当 Kylin 执行这一步时，您可以监视 Yarn 资源管理器里的状态. 点击 “Application Master” 链接将会打开 Spark 的 UI 网页，它会显示每一个 stage 的进度以及详细的信息。

![](https://main.qcloudimg.com/raw/3dcb972a2f7d8084dd7fad887d1e2953.png)
所有步骤成功执行后，Cube 的状态变为 “Ready” 且您可以像往常那样进行查询。





